{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadiajelani/wound-detection/blob/main/Wound_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow pillow numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epqsLwJgkvIE",
        "outputId": "4b146d4f-e8c2-4403-cc73-66de95fd9641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C_aoC8dmwSB",
        "outputId": "97c8d3a0-034b-4eeb-cf3a-51d7d0f1dcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def train_wound_cnn_model(data_dir, save_path=\"wound_cnn_model.h5\"):\n",
        "    # Data augmentation and normalization\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "    # Training and validation data generators\n",
        "    train_generator = datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training'\n",
        "    )\n",
        "    val_generator = datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "    # Debugging dataset loading\n",
        "    if train_generator.samples == 0:\n",
        "        raise ValueError(\"No training images found. Check your dataset structure and path.\")\n",
        "    if val_generator.samples == 0:\n",
        "        raise ValueError(\"No validation images found. Check your dataset structure and path.\")\n",
        "\n",
        "    # CNN Model\n",
        "    model = Sequential([\n",
        "        Input(shape=(128, 128, 3)),  # Define input shape explicitly\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification: infected/non-infected\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Save the model\n",
        "    model.save(save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Train and save the model\n",
        "train_wound_cnn_model(\"/content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset\", \"/content/drive/MyDrive/Colab Notebooks/Jay Jelani/wound_cnn_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NxYUBLnoWrA",
        "outputId": "1b300efe-bcf4-45e0-e8ab-aeb379fd1090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 162 images belonging to 3 classes.\n",
            "Found 39 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.3817 - loss: -3.5047 - val_accuracy: 0.4359 - val_loss: -32.4419\n",
            "Epoch 2/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 651ms/step - accuracy: 0.4582 - loss: -67.7083 - val_accuracy: 0.4359 - val_loss: -220.3801\n",
            "Epoch 3/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 789ms/step - accuracy: 0.4421 - loss: -379.0518 - val_accuracy: 0.4359 - val_loss: -810.3500\n",
            "Epoch 4/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 649ms/step - accuracy: 0.4331 - loss: -1223.5098 - val_accuracy: 0.4359 - val_loss: -2244.0977\n",
            "Epoch 5/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.4301 - loss: -3257.8750 - val_accuracy: 0.4359 - val_loss: -5454.5815\n",
            "Epoch 6/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 637ms/step - accuracy: 0.4130 - loss: -7242.2036 - val_accuracy: 0.4359 - val_loss: -10755.4902\n",
            "Epoch 7/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4386 - loss: -14693.1406 - val_accuracy: 0.4359 - val_loss: -19976.1641\n",
            "Epoch 8/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 637ms/step - accuracy: 0.4294 - loss: -26935.8789 - val_accuracy: 0.4359 - val_loss: -36356.2305\n",
            "Epoch 9/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 651ms/step - accuracy: 0.4518 - loss: -49460.7852 - val_accuracy: 0.4359 - val_loss: -62736.6797\n",
            "Epoch 10/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 983ms/step - accuracy: 0.4302 - loss: -82795.3438 - val_accuracy: 0.4359 - val_loss: -103375.1641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/Colab Notebooks/Jay Jelani/wound_cnn_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageDraw\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tkinter import Tk, filedialog, Button\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "3wlztvWikyH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model for feature extraction\n",
        "base_model = ResNet50(weights='imagenet')\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
        "\n",
        "# Load the U-Net model for segmentation\n",
        "try:\n",
        "    unet_model = load_model('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/unet_model.h5')\n",
        "except IOError:\n",
        "    print(\"Error: U-Net model file could not be loaded. Check the file path.\")\n",
        "    unet_model = None\n",
        "\n",
        "# Load the CNN model for wound classification and compile it\n",
        "try:\n",
        "    cnn_model = load_model('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/wound_cnn_model.h5')\n",
        "    cnn_model.compile(loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
        "except IOError:\n",
        "    print(\"Error: CNN model file could not be loaded. Check the file path.\")\n",
        "    cnn_model = None\n",
        "\n",
        "# Global variables to control capturing and directory path\n",
        "is_capturing = True\n",
        "save_directory = \"\"\n",
        "latest_image_path = \"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtZgqE4Pk1DL",
        "outputId": "0c2a833e-0240-42b2-993e-6131c5e4530a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CNN model for wound classification and compile it\n",
        "try:\n",
        "    cnn_model = load_model('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/wound_cnn_model.h5')\n",
        "    cnn_model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
        "except IOError:\n",
        "    print(\"Error: CNN model file could not be loaded. Check the file path.\")\n",
        "    cnn_model = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW1GYDf25fk-",
        "outputId": "51260c67-55a0-495d-9ffc-454e52d335c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the U-Net model for segmentation\n",
        "try:\n",
        "    unet_model = load_model('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/unet_model.h5')\n",
        "    unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "except IOError:\n",
        "    print(\"Error: U-Net model file could not be loaded. Check the file path.\")\n",
        "    unet_model = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csmb4t_75foV",
        "outputId": "07385a3a-4aeb-4f5b-d3a3-b995dde25392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load your U-Net model\n",
        "unet_model = load_model('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/unet_model.h5')\n",
        "\n",
        "# Define paths\n",
        "input_folder = '/content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/infected'\n",
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks'\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Function to create and save masks\n",
        "def create_masks(input_folder, output_folder, model, img_size=(128, 128)):\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        if file_name.endswith(('.jpg', '.png', '.jpeg')):  # Check for valid image formats\n",
        "            image_path = os.path.join(input_folder, file_name)\n",
        "            save_path = os.path.join(output_folder, file_name)\n",
        "\n",
        "            # Load and preprocess image\n",
        "            image = imread(image_path)\n",
        "            image_resized = resize(image, img_size)  # Resize to model's input size\n",
        "            image_preprocessed = np.expand_dims(image_resized / 255.0, axis=0)  # Normalize and add batch dimension\n",
        "\n",
        "            # Predict mask\n",
        "            predicted_mask = model.predict(image_preprocessed)[0]\n",
        "            binary_mask = (predicted_mask > 0.5).astype(np.uint8)  # Convert to binary mask\n",
        "\n",
        "            # Save mask\n",
        "            mask_image = Image.fromarray(binary_mask.squeeze() * 255)  # Scale to [0, 255]\n",
        "            mask_image.save(save_path)\n",
        "\n",
        "            print(f\"Mask created and saved: {save_path}\")\n",
        "\n",
        "# Create masks for all images\n",
        "create_masks(input_folder, output_folder, unet_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5RRQifO8PtU",
        "outputId": "44934dca-8ea8-4e1d-e385-791d2d8bafcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c9514185a0779a67ab879ba57b1b4330_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bff9ae20248b28c7f3d7021c1a3a03aa_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/baba5451a41a555f6ea4355b4c53db59_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c13b32121da4b50bcdca469a79b5e7e0_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c2313e2f7edbaa2a6286e3284fff445a_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/ba4755da013537410deae3f8386d08ba_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c69dcb7ad054b063cd0470aa944cf01e_2.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c21f26f8179c00b39d1426b089b30b2f_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c8cf2da63be1a27497baa852387fe31f_2.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c004670497036e3dfeb5273bb7a10078_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c1a8b5b3cef9b103fb5b150f3d90059b_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/b23232898bafcf304b2138af86be40b9_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c89d9e02226bdc10e8e259f6cd2e3b63_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cae0a471fae3ff8bb9c02293613e9c73_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c45524e9ced14e2f2c2830fd8fc24b24_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c597b0deca08c4a4ff2679f23fc007ad_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bbfe627c5a6d2322d419a10720b9219c_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c56e05444de7e0cbb9388c6317e9d7c5_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c3b9e7bd99ebf6148dbee204647d21f2_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c246ad5018b38f053c8759df84a23601_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bb7f8181ab26743700a45af24d7bc47b_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c69dcb7ad054b063cd0470aa944cf01e_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c9a38a5f6f6231d7a3b27a782002975a_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bffbabdaa62239b903069228afa4de20_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cae42b39ca992138485e9212dda3d9c0_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/b61269467f2dc93f3cc31f933fa7013a_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bb7f8181ab26743700a45af24d7bc47b_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c265c21a78fbc8365180265e1332d004_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c8cb5cde1cc95b62bf63a8c980c26172_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c95105b1727344ae36f8dca2a1ba4543_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c8cb5cde1cc95b62bf63a8c980c26172_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c0bdf99bc8fb893424093cc880e92d68_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c2a990b5b28deba70260ed8bf792ec7b_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c8b2c366e585c47212fb27fb1791819c_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bf4af9461cdc6932d0314ba3245448b3_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c600577c4530dca824f9bea3ee4cd3e5_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cc89d9cbb5bf15efc483526cdf9f0082_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cc0468314bc8131fd99ccbda215002ef_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/be4f560ee458e7d3be3f6fa606fbdc65_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cc89d9cbb5bf15efc483526cdf9f0082_2.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bdbab63e08219299b187e057d9a7b783_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cb49f7106d1dc57f31fd4cd43918226c_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bb59a635e988cbe2323c92ff2bb04e91_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c13f6d11078cf3a4ee57b76fc8c5dd2c_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c95105b1727344ae36f8dca2a1ba4543_3.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/ba4755da013537410deae3f8386d08ba_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c1ecb35c7bb04baeb2ce3ea6a7c43524_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c2c6887f393a922fe5abf12988e09cac_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/ba00cb9444f74badd3afada2bd3d6642_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c4352e791702719ed4ef770e305372f9_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c0d3bfec69153f1cb8556a17fe12faa2_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bf4af9461cdc6932d0314ba3245448b3_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c48203372370072e4dbf236b1a2bb5bb_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cc89d9cbb5bf15efc483526cdf9f0082_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cc99e6b20ced333bcf27d6e6f1a70eb1_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bb267b1abca1c53df371bc15bf592070_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c95105b1727344ae36f8dca2a1ba4543_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/be4c8e6e241704330a2835daa99f732f_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bbcede236aef5e690eb18bb7cc585c69_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cb17569424d3c73fe71071ad8166acf2_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c48662d86ee00a6e011a972daf8edc09_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c9cd6236058744e90aae5ffc8f461f9c_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c8cf2da63be1a27497baa852387fe31f_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/baf6df704ae535e46fe2f366a58f219c_3.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/ca7f1d6a3136067a18843121a079ae09_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cc80544140c26be0c69e6d060884d070_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bbf82a8180020c2a8b38e6f8c7c86d7d_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/baf6df704ae535e46fe2f366a58f219c_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/be3e8ff2ee8047c2ae0f47864dadeaae_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/baf6df704ae535e46fe2f366a58f219c_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c4917d2864b89a6054cbdbc1d383e927_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cb22ef69d6adf0a06e5cc8041f61e08b_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c67fddd7b6f3d98dc0afc82e0d9d06e4_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c004670497036e3dfeb5273bb7a10078_2.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c147a0982732a3b9ffd4ed05f0c52590_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c95105b1727344ae36f8dca2a1ba4543_2.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c004670497036e3dfeb5273bb7a10078_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/b586407933e66b112820f28448783627_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/cc80544140c26be0c69e6d060884d070_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bddd694789472ca2f679ca9263576c4c_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/baba5451a41a555f6ea4355b4c53db59_1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bc29987427c1c3995fd2109e730a4336_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c6d01bfe1f8d1f9aa5404e64e114f0ee_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c004670497036e3dfeb5273bb7a10078_3.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c8cf2da63be1a27497baa852387fe31f_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c147a0982732a3b9ffd4ed05f0c52590_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/c4d1e43b2a2a41377c8ce2194160bc70_0.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/baf6df704ae535e46fe2f366a58f219c_2.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "Mask created and saved: /content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset/masks/bc6afdb212331d00685eae069e455957_0.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define paths\n",
        "input_folder = '/content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset'\n",
        "\n",
        "def train_cnn_model(input_folder):\n",
        "    # Check if the input folder exists\n",
        "    if not os.path.exists(input_folder):\n",
        "        raise ValueError(f\"Input folder '{input_folder}' does not exist. Please check the path.\")\n",
        "\n",
        "    # Check subdirectories for classes\n",
        "    classes = os.listdir(input_folder)\n",
        "    if len(classes) < 2:\n",
        "        raise ValueError(f\"Input folder '{input_folder}' should contain at least two subdirectories (e.g., 'infected' and 'non_infected'). Found: {classes}\")\n",
        "\n",
        "    # Data augmentation and data generator\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "    try:\n",
        "        train_gen = datagen.flow_from_directory(\n",
        "            input_folder,\n",
        "            target_size=(128, 128),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            subset='training'\n",
        "        )\n",
        "\n",
        "        val_gen = datagen.flow_from_directory(\n",
        "            input_folder,\n",
        "            target_size=(128, 128),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            subset='validation'\n",
        "        )\n",
        "\n",
        "        # Check if data generators loaded samples\n",
        "        if train_gen.samples == 0:\n",
        "            raise ValueError(f\"No training images found in '{input_folder}'. Please check the folder structure.\")\n",
        "        if val_gen.samples == 0:\n",
        "            raise ValueError(f\"No validation images found in '{input_folder}'. Please check the folder structure.\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error initializing data generators: {e}\")\n",
        "\n",
        "    # Define the CNN model\n",
        "    cnn_model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the CNN model\n",
        "    cnn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the CNN model\n",
        "    try:\n",
        "        cnn_model.fit(\n",
        "            train_gen,\n",
        "            validation_data=val_gen,\n",
        "            epochs=20,\n",
        "            batch_size=32\n",
        "        )\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error during training: {e}\")\n",
        "\n",
        "    # Save the model\n",
        "    try:\n",
        "        cnn_model.save('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/wound_cnn_model_trained.h5')\n",
        "        print(\"CNN model saved as 'wound_cnn_model_trained.h5'\")\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error saving model: {e}\")\n",
        "\n",
        "# Call the function to train the CNN model\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        train_cnn_model(input_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "4wFkCqDKNFQC",
        "outputId": "6251aa38-07db-4b24-974b-5efd0b54ebb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input folder '/content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset' does not exist. Please check the path.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ac603dac555f>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Call the function to train the CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtrain_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-ac603dac555f>\u001b[0m in \u001b[0;36mtrain_cnn_model\u001b[0;34m(input_folder)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Check if the input folder exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input folder '{input_folder}' does not exist. Please check the path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Check subdirectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input folder '/content/drive/MyDrive/Colab Notebooks/Jay Jelani/dataset' does not exist. Please check the path."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageEnhance, ImageDraw\n",
        "from tensorflow.keras.models import load_model\n",
        "from datetime import datetime\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Load the trained U-Net model\n",
        "try:\n",
        "    unet_model = load_model('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/unet_model.h5')\n",
        "    logging.info(\"U-Net model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load U-Net model: {e}\")\n",
        "    unet_model = None\n",
        "\n",
        "# Load the trained CNN model\n",
        "try:\n",
        "    cnn_model = load_model('/content/drive/MyDrive/Colab Notebooks/Jay Jelani/wound_cnn_model.h5')\n",
        "    logging.info(\"CNN model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load CNN model: {e}\")\n",
        "    cnn_model = None\n",
        "\n",
        "\n",
        "# Image Capture\n",
        "def capture_image(save_directory):\n",
        "    \"\"\"\n",
        "    Captures an image using the webcam and saves it to the specified directory.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(save_directory):\n",
        "            os.makedirs(save_directory)\n",
        "\n",
        "        # Start the webcam\n",
        "        cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(\"Cannot access webcam\")\n",
        "\n",
        "        logging.info(\"Press 'c' to capture the image or 'q' to quit.\")\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                logging.error(\"Failed to capture frame from webcam.\")\n",
        "                break\n",
        "\n",
        "            # Show live feed\n",
        "            cv2.imshow(\"Webcam - Press 'c' to capture\", frame)\n",
        "\n",
        "            # Check for keypress\n",
        "            key = cv2.waitKey(1) & 0xFF\n",
        "            if key == ord('c'):  # Capture image\n",
        "                image_path = os.path.join(save_directory, 'captured_image.jpg')\n",
        "                cv2.imwrite(image_path, frame)\n",
        "                logging.info(f\"Image captured and saved to {image_path}\")\n",
        "                cap.release()\n",
        "                cv2.destroyAllWindows()\n",
        "                return image_path\n",
        "            elif key == ord('q'):  # Quit\n",
        "                logging.info(\"Capture cancelled.\")\n",
        "                cap.release()\n",
        "                cv2.destroyAllWindows()\n",
        "                return None\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during image capture: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Image Enhancement\n",
        "def enhance_image(image_path):\n",
        "    \"\"\"\n",
        "    Enhances the detail of an image and saves it back to the same path.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        enhancer = ImageEnhance.Detail(img)\n",
        "        img_enhanced = enhancer.enhance(1.5)  # Adjust enhancement level\n",
        "        img_enhanced.save(image_path)\n",
        "        logging.info(f\"Image enhanced and saved to {image_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error enhancing image: {e}\")\n",
        "\n",
        "\n",
        "# Segmentation and Labeling\n",
        "def segment_and_label_wound(image_path):\n",
        "    \"\"\"\n",
        "    Segments and labels wound areas on an image.\n",
        "    \"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    mask_image = segment_image_with_unet(image_path)\n",
        "\n",
        "    if mask_image is None:\n",
        "        logging.error(\"Segmentation could not be completed.\")\n",
        "        return None, None\n",
        "\n",
        "    # Resize mask to original image size\n",
        "    mask_resized = mask_image.resize(img.size)\n",
        "    mask_np = np.array(mask_resized)\n",
        "\n",
        "    # Convert mask to binary and find contours\n",
        "    _, binary_mask = cv2.threshold(mask_np, 127, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    labeled_image = img.copy()\n",
        "    draw = ImageDraw.Draw(labeled_image)\n",
        "    wound_areas = []\n",
        "\n",
        "    # Process each contour\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        draw.rectangle([(x, y), (x + w, y + h)], outline=\"green\", width=2)  # Draw bounding box\n",
        "\n",
        "        # Classify wound area\n",
        "        label, confidence = classify_wound_area(img, (x, y, w, h))\n",
        "        draw.text((x, y - 10), f\"{label} ({confidence:.2f})\", fill=\"green\")\n",
        "        wound_areas.append((x, y, w, h, label, confidence))\n",
        "\n",
        "    # Save labeled image\n",
        "    labeled_image_path = image_path.replace('.jpg', '_labeled.jpg')\n",
        "    labeled_image.save(labeled_image_path)\n",
        "    logging.info(f\"Labeled image saved to {labeled_image_path}\")\n",
        "    return labeled_image_path, wound_areas\n",
        "\n",
        "\n",
        "# Full Processing Pipeline\n",
        "def process_image(image_path):\n",
        "    \"\"\"\n",
        "    Full pipeline to enhance an image, segment it, classify wounds, and save results.\n",
        "    \"\"\"\n",
        "    enhance_image(image_path)\n",
        "    labeled_image_path, wound_areas = segment_and_label_wound(image_path)\n",
        "    if wound_areas:\n",
        "        export_report(image_path, wound_areas)\n",
        "\n",
        "\n",
        "# Export Report\n",
        "def export_report(image_path, wound_areas):\n",
        "    \"\"\"\n",
        "    Exports a detailed wound analysis report.\n",
        "    \"\"\"\n",
        "    report_path = image_path.replace('.jpg', '_report.txt')\n",
        "    try:\n",
        "        with open(report_path, 'w') as report:\n",
        "            report.write(f\"Wound Analysis Report - {datetime.now()}\\n\")\n",
        "            report.write(f\"Image Path: {image_path}\\n\")\n",
        "            report.write(\"Detected Wound Areas (in pixels):\\n\")\n",
        "            for area in wound_areas:\n",
        "                x, y, w, h, label, confidence = area\n",
        "                report.write(f\"- Position: ({x}, {y}), Size: ({w}x{h}), Label: {label}, Confidence: {confidence:.2f}\\n\")\n",
        "            total_area = sum(area[2] * area[3] for area in wound_areas)\n",
        "            report.write(f\"Total Wound Area: {total_area} pixels\\n\")\n",
        "        logging.info(f\"Report saved to {report_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating report: {e}\")\n",
        "\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    save_directory = '/path/to/save/directory'  # Replace with your directory path\n",
        "    captured_image_path = capture_image(save_directory)\n",
        "\n",
        "    if captured_image_path:\n",
        "        process_image(captured_image_path)\n",
        "    else:\n",
        "        logging.info(\"No image captured. Exiting.\")\n"
      ],
      "metadata": {
        "id": "SnVAMxbKlIxc"
      },
      "execution_count": 3,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}